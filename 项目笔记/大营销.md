## 大营销平台-第一阶段梳理

### 前置知识：ddd架构设计

> 暂时没写

### 第一阶段-数据库表设计

strategy：策略表，定义一个抽奖策略，不同的策略下可以配置不一样的策略奖品，策略规则，增强抽奖可玩性。需要配合stratgt_rule实现黑名单功能

strategy_rule：策略规则表，用于定义抽奖的前置规则配置，如果用户达到xx积分可以抽中对应配置的奖池。如果用户是黑名单则不给好奖品

strategy_award:策略奖品表：一个抽奖策略下的所有奖品，包括抽奖基本信息，和奖品对应的规则树配置

rule_tree：规则树总表，把规则树整体信息暴露给奖品表使用，主要外键是树的根节点

rule_tree_node：规则树节点，和具体的java规则节点类一一对应，用来实现一些复杂业务的规则过滤

rule_tree_line:规则树的边边，指定了规则的路径。

### 第一阶段-抽奖算法实现，并加载概率到缓存

#### 两种抽奖算法介绍

第一种：**时间换空间**的抽奖算法，时间复杂度ON，空间复杂度O1,不需要额外内存

> 定义三个奖品，A:50 B:20 C:30。随机生成一个0到100的数字
>
> 遍历这三个奖品：设置一个计数器累加这个奖品的概率，如果随机数在0到50范围内，则中奖A
>
> 否则继续加B奖品概率，如果随机数在50到70范围内，则中奖B

第二种：**空间换时间**的抽奖算法

> 还是三个奖品 A:50 B:20 C:30。以最小的概率为单位1，这里是B：20。总范围：100，那么把空间分成5份。
>
> 遍历每个奖品，计算自己占多少个单位1
>
> A:占2.5个，但是统一向上取整。取3个，所以往map里放三个A奖品
>
> B：占一个：map里加一个B
>
> C：1.5个，map里加两个C。
>
> 这样可以得到一个AAABCC的map，乱序之后，根据随机值进行哈希定位取出元素即可。**时间复杂度为O1**
>
> **上述设计会出现概率不准确的情况，需要进行优化修改**
>
> 小傅哥平台实际实现算法：遍历每个奖品，×上rateRange，rageRange=概率总和/最小概率
>
> **其实也没有解决这个问题**
>
> 可以对概率进行整数化并求和，和就是map长度，每一个化整后的概率值都循环写入map
>
> 例如：概率为0.4 0.2  0.31，找出小数点后最长的小数直接全部*100，然后分别放4，2，31个奖品入map。
>
> **缺点是很容易产生OOM**

### 第一阶段-带权重范围的概率值装配

1.根据策略id查询策略规则，找到rule_model= rule_weight的记录，然后取出来

2.取出这个实体的ruleValue值并在实体对象里面提供解析的方法，可以直接解析ruleValue，得到一个Map

3.这个map结构是【【key-4000：102，103   value-102，103】【key-5000：101，102，103   value-101，102，103】【key-6000：107，108   value-107，108】】

4.遍历key，取出这个奖品id集合，使用stream流操作已有总奖品列表，如果已有奖品列表里的奖品不在这个id集合里面，则remove掉。调用装配概率算法，传入处理好的奖品列表

5.缓存key和map的key一样。

### 第一阶段-责任链处理抽奖前置规则过滤

需求-需要将黑名单和权重配置的规则处理掉：如果用户是黑名单直接返回积分，否则走进权重。如果权重规则不符合，放行走默认抽奖。如果权重规则符合，则进行权重抽奖，走必中抽奖。

1.定义工厂，把三个责任链实现类创建处理并用component("")配合map构造函数实例化具体的责任链group。

```
@Service
public class DefaultChainFactory {
    private final Map<String, ILogicChain> logicChainGroup;

    private final IStrategyRepository repository;


    public DefaultChainFactory(Map<String, ILogicChain> logicChainGroup, IStrategyRepository repository) {
        this.logicChainGroup = logicChainGroup;
        this.repository = repository;
    }

```

2.提供openChain方法，把责任链节点具体构造成链条

3.使用责任链：在实际抽奖接口中定义注入默认责任链工厂，开启责任链，并执行。

4.定义奖品VO和ruleModelVO内部类，在责任链的内部流转。

### 第一阶段-规则树处理中置规则


### 第一阶段-抽奖库存扣减配合redis锁详解

#### 首先，当前只有进入到库存扣减规则树的奖品才会扣减库存，并且已经完成了缓存预热

实现库存扣减大体分为两步：1.扣减redis库存，2.发送延迟队列（缓解mysql压力）

对于1会返回一个boolean值，false代表加锁失败，那么这时候有可能是：**没库存了**或者**获取锁超时了**。也就代表有线程正在执行任务阻塞了挺久，那么后续线程会直接获取不到锁并且放弃。这叫redisson获取锁超时释放。返回false后可以进行兜底返回积分，也可以返回给前端友好的提示【当前奖品被抢完了/当前抽奖人数过多】。

**面试问题：如果一个业务阻塞了，应该怎么做？答：超时释放的线程应该进入兜底方案。**

加的锁key：以奖品id和奖品id剩余库存为key加锁。**重点：线程1对105：100先扣减，再lock住105：99，那么线程2也可以获取锁，锁住的shi！因为锁是分段的，只要不超卖就可以了！**

既然不会发生竞争，那么加锁的目的是什么？**防止因为某些异常导致从96库存恢复98之后，又扣减了96的库存，照成了超卖。**

**如果库存要改变，怎么办？答：可以采用incr方式，超卖问题和库存原有值＋变更值对比就行了**


### 面试话术

我的负责了抽奖平台的核心模块-抽奖模块的开发与设计。首先是定义了一个抽象的抽奖类作为模板，采用**模板模式**定义抽奖流程，将具体实现交给实现类。提高可迭代性，易维护。那么我的抽奖流程是这样：首先是进行一些参数校验，然后就走责任链模式过滤抽奖前置动作-过滤一下黑名单或者权重配置，如果都没有被拦截，则进入默认抽奖责任链（抽奖算法调度）返回一个奖品id，再走库存扣减逻辑。对于库存扣减，为了防止库存超卖，我是用redis的decr操作和0进行判断，还对奖品id和每一个线程扣减后的数量作为key，进行加锁兜底，防止恢复库存的时候对同一个库存余额重复卖，又超卖了。库存扣减成功后立马发送redis延迟队列，并开启一个spring定时任务来处理任务，防止瞬时高并发压垮mysql。




---

# 前面的内容等有空再补充

## 关于大营销-第二阶段-有关额度的操作与查询问题：

### 前端刷新的时候直接查询今日剩余抽奖次数

这个逻辑是先查总账户，如果还没有总账户则创建总账户，如果日月表有优先返回日月表的，否则返回总账户的（这里就有个问题：我昨天的总账户中日剩余100，今天还没日表，那么今天剩余抽奖次数就和昨天剩余的一样了）

### 前端查询今天已经抽奖次数

这个逻辑是要查日表的，如果还没日表，就是0。

### 抽奖的时候扣减额度

日表和总表都扣减，这个时候如果没有日表则会新建一张日表(xfg这里创建日表用的是总账户的日数据，也就延用了旧数据)，也就是我说的问题（我今天抽奖是0次，但是你却同步了昨天的数据给我）

### 签到领取活动后，MQ接收到返利行为，则调用创建活动订单，增加额度

增加额度的时候，也是总表和日表都一起加，没有日表则不管

### 次数锁校验

这个是直接查日表，不用担心不存在，因为在扣减额度的时候日表就刷新了。

### 分段必中范围的抽奖次数

这个是通过直接查询账户余额来进行的，同1.区别是前端想怎么设计就用哪个（比如想用总的，想用月的抽奖次数来作为值去解锁奖池都可以）

##### 解决方案：1.增加定时任务，每天凌晨把这个总账户的日额度清空，这样的话就没错了。2.在扣减额度的时候如果没有日额度则直接设为0，这样才是对的逻辑

## 大营销-部署思路与问题排查

### 1.部署环境

这个没啥的，根据给的docker-compose-environment.yml部署就完事了

### 2.部署前端（先把整个前端项目git拉到云服务器）

前端主要坑：主要是一定要把.env.local上传，不然apis文件夹里面定义的请求发送不到后端，而且部署上云之前一点更要修改这个API_HOST_URL，指向后端服务器的地址，才能正常发请求到后端

> 另外，还要注意build镜像时出warning不用管，进度条卡了是因为网络太慢了

### 3.部署后端（先把整个后端项目git拉到云服务器）

构建镜像-首先需要服务器安装maven并且配置，install然后打包，执行build脚本

### 4.通过docker-compose启动前后端容器

后端：可以通过修改docker-compose文件动态传递配置文件的内容，把redis和mysql写成本地地址，实现docker容器内互通。
前端：暂时不能通过变量直接修改请求路径。注意后端和中间件一定要在同一个docker网络下，要求是：使用同一个文件夹运行docker-compose
启动完成，可以通过portainer看日志
